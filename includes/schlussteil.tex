\chapter[Kritische Reflexion und Ausblick]{Kritische Reflexion und Ausblick\footnote{Sprachlich geglättet durch ChatGPT-5}}
\label{chapter:Ergebnisdiskussion}

\section{Auftrag der Arbeit}
Das zentrale Ziel dieser Arbeit war die Entwicklung einer Pipeline zur automatisierten Generierung synthetischer Bilddaten für das Training von \ac{KI}-Modellen zur Fehlererkennung bei Werkzeugmaschinen. Dieses Ziel ergab sich aus der in der Forschungsliteratur beschriebenen Problematik, dass insbesondere im industriellen Kontext häufig nur unzureichende oder einseitige reale Daten für das Training von \ac{KI}-Modellen zur Verfügung stehen.\footnote{Vgl. Kapitel \ref{sec:problemstellung}}

Um diesen Datenmangel zu adressieren, wurde eine Datenpipeline konzipiert, welche eine einfache und flexible Generierung umfangreicher, ausgeglichener und realistischer synthetischer Datensätze ermöglicht. Darüber hinaus sollten verschiedene \ac{KI}-Modelle auf diesen generierten Daten trainiert werden, um die Eignung synthetischer Daten zu validieren.

Im praktischen Teil der Arbeit wurde daher eine Simulationsumgebung in \textit{NVIDIA Omniverse} aufgebaut und eine Pipeline zur automatisierten Generierung synthetischer Bilddaten implementiert, bei welcher zentrale Parameter hinsichtlich der Bildqualität, der Anzahl der Bilder und der Simulationsumgebung einfach modifiziert werden konnten. Diese Daten wurden in ein für das Modelltraining geeignetes Format überführt und die Eignung und Qualität der generierten Daten durch ein Training von drei Varianten der \ac{YOLO}-Architektur sowie ein transformerbasiertes Modell validiert. Als methodische Grundlage diente dabei das \ac{DSR}-Paradigma, welches es ermöglichte, das entwickelte Artefakt in einem iterativen Prozess zu evaluieren und zu verbessern.


\section{Kritische Reflexion der Methodik und Ergebnisse}

Die Ergebnisse der Evaluation zeigen, dass die entwickelte Pipeline erfolgreich synthetische Bilddaten generieren konnte, welche konsistent waren und sich für das Training von \ac{KI}-Modellen eigneten. Alle trainierten \ac{YOLO}-Modelle konnten auf dem synthetischen Testdatensatz eine gute Leistung erbringen und auch ihr Trainingsverlauf sah vielversprechend aus. Zwar zeigte die transformerbasierten Modelle hier deutlich schlechtere Ergebnisse, dies lässt sich jedoch nicht unmittelbar auf die Qualität der generierten Daten zurückführen, da die CNN-basierten Modelle konsistente Resultate erbrachten. Damit kann die Forschungsfrage der Arbeit, wie synthetische Daten für das Training von \ac{KI}-Modellen zur Fehlererkennung bei Werkzeugmaschinen genutzt werden können und inwieweit die daraus generierten synthetischen Daten für den Einsatz in realen Anwendungsfällen geeignet sind, grundsätzlich beantwortet werden.

Der fehlende Erfolg beim Transfer auf reale Daten kann verschiedene Gründe haben und ist nicht zwangsläufig auf die Qualität oder den mangelnden Realismus der generierten Daten zurückzuführen. Wie schon in Tabelle \ref{tab:yolo_results} zu sehen ist, erzielte das größte trainierte \ac{YOLO}-Modell auf dem realen Datensatz bessere Ergebnisse als kleinere Modelle. Dies legt nahe, dass die Modellgröße ein entscheidender Faktor für die Übertragbarkeit sein kann. Insbesondere bei transformerbasierten Modellen spielt außerdem die Größe und Vielfalt des Datensatzes eine zentrale Rolle, da ihre Leistung in besonderem Maße von umfangreichen Trainingsdaten abhängt.\footnote{Vgl. \cite[8]{jamil_comprehensive_2022}; \cite[209]{berroukham_vision_2023}} Der Schwerpunkt dieser Arbeit lag außerdem nicht auf der Optimierung der Modelleistung, beispielsweise durch die Ermittlung optimaler Hyperparameter, sondern auf der Konzeption und Umsetzung der Pipeline zur Generierung synthetischer Daten.

Es ergaben sich im Verlauf der Umsetzung und Evaluation des weiteren diverse Herausforderungen und Limitationen, welche den Umfang und die Qualität der generierten Daten sowie die Leistung der \ac{KI}-Modelle beeinflusst haben:

\begin{itemize}
    \item \textbf{Rechenleistung und Ressourcen}: Das Training stieß insbesondere bei den größeren Modellen auf Hardware- und Zeitbeschränkungen. Die begrenzte Rechenleistung wirkte sich sowohl auf den Realismus als auch auf den Umfang der generierten Daten aus. Auch die Auswahl der Größe der \ac{KI}-Modelle wurde durch die verfügbare Hardware limitiert, was insbesondere die Übertragbarkeit auf reale Daten beeinträchtigt haben könnte.
    \item \textbf{Umfang und Qualität der Daten}: Der synthetische Datensatz umfasste lediglich eine begrenzte Anzahl von Fehlerfällen, Perspektiven und Variationen. Die Größe des Datensatzes war mit 1.077 Bildern relativ klein, was die Generalisierungsfähigkeit und Leistung der Modelle eingeschränkt haben könnte.
    \item \textbf{Fehlerquellen in der Datengenerierung}: Unerwartete Fehler wie etwa ungewollte Objektrotationen oder fehlerhafte Annotationen durch den \textit{Omniverse Replicator} führten wiederholt zu Verzögerungen.
    \item \textbf{Modellarchitekturen}: Während die \ac{YOLO}-Modelle auf synthetischen Daten konsistente Ergebnisse lieferten, zeigte das transformerbasierte \ac{RT-DETR}-Modell eine deutlich geringere Leistung. Ursachen hierfür können im kleinen Datensatz, in einer unzureichenden oder fehlerhaften Datenaugmentierung sowie in fehlender Expertise bei der Konfiguration von Transformermodellen und deren Hyperparametern liegen.
\end{itemize}

Das \ac{DSR}-Paradigma erwies sich als geeignete Methodik, um die Entwicklung der Pipeline zu strukturieren und iterative Verbesserungen basierend auf den Evaluationsergebnissen vorzunehmen. Es konnten somit Fehler frühzeitig erkannt und korrigiert sowie die Modelleistungen und Datenqualität stetig verbessert werden. Schlussendlich wäre jedoch eine intensivere Auseinandersetzung mit verschiedenen \ac{KI}-Architekturen und deren konkreten Anforderungen an Trainingsdaten, Datenaugmentation und Hyperparameter-Konfigurationen für die Evaluation der Datenpipeline hilfreich gewesen, da aktuell zahlreiche Parameter Einfluss auf die erzielten Ergebnisse haben könnten. Dies war jedoch aufgrund zeitlicher Limitationen nur eingeschränkt möglich. Auch die Anzahl der iterativen Trainings- und Evaluationsdurchläufe wurde durch die zeitlichen Beschränkungen limitiert. Weitere Iterationen hätten die Qualität der Daten sowie die Leistung der Modelle weiter verbessern können.


\section{Implikationen für die Forschung}
Die Ergebnisse machen deutlich, dass der Einsatz synthetischer Daten ein hohes Potenzial bietet, jedoch weitere Forschung notwendig ist, um die Übertragbarkeit auf reale Anwendungsfälle zu verbessern:

\begin{itemize}
    \item \textbf{Effizientere Simulationssoftware}: Die eingesetzte Software \textit{NVIDIA Omniverse} bietet zwar eine hohe Flexibilität und einen hohen möglichen Realismus, ist jedoch sehr ressourcenintensiv.\footnote{Vgl. \cite{noauthor_isaac_nodate}} Alternativ könnte die Nutzung von effizienteren Simulationssoftware wie beispielsweise \textit{Genesis}\footnote{Vgl. \cite{noauthor_genesis-embodied-aigenesis_2025}} untersucht werden, die speziell auf Effizienz und geringere Hardwareanforderungen ausgelegt ist.
    \item \textbf{Größere und realistischere Datensätze}: Für eine bessere Generalisierungsfähigkeit sollten mehr Daten mit höherer Variabilität und höhere Qualität generiert werden. Hierzu zählen zusätzliche Fehlerklassen, variierende Perspektiven sowie realitätsnähere Darstellungen, sodass ein größerer und umfangreicherer Datensatz für das Training der \ac{KI}-Modelle zur Verfügung steht.
    \item \textbf{Leistungsfähigere Modelle}: Die erzielten Ergebnisse deuten darauf hin, dass größere Modelle besser geeignet sein könnten, um den \textit{Domain Gap} zu überbrücken. Dies setzt jedoch eine deutlich höhere Rechenleistung sowie die Möglichkeit für längere Trainingszeiten voraus.
    \item \textbf{Diffusionsmodelle}: Um den Realismus der synthetischen Bilddaten zu erhöhen, ohne die Hardwareanforderungen unverhältnismäßig zu steigern, könnte der Einsatz von Diffusionsmodellen eine vielversprechende Möglichkeit darstellen. Hierbei werden synthetisch generierte Bilddaten genutzt und anschließend Oberflächen und Materialien durch den Einsatz eines Diffusionsmodells realistischer gestaltet.\footnote{Vgl. \cite{hadadan_generative_2025}}
    \item \textbf{Hybrides Training}: Eine vielversprechende Möglichkeit besteht darin, synthetische und reale Daten kombiniert einzusetzen. Dabei wird das Modell auf synthetischen Daten trainiert und anschließend ein \textit{Fine-Tuning} auf realen Daten durchgeführt. Ein solches hybrides Training könnte die Generalisierungsfähigkeit der Modelle verbessern und den \textit{Domain Gap} verringern.\footnote{Vgl. \cite[17]{zaripov_creation_2025}}
    \item \textbf{Architekturen}: Die Eignung weiterer Architekturen, wie beispielsweise die eines \ac{HVT}, die Elemente von \ac{CNN}- und Transformer-Ansätzen kombiniert, könnte untersucht werden.\footnote{Vgl. \cite[S. 4 f.]{khan_survey_2023}}
\end{itemize}

Es lässt sich insgesamt feststellen, dass insbesondere in Hinblick auf das Remote Monitoring von Werkzeugmaschinen, der Einsatz von synthetischen Daten eine vielversprechende Möglichkeit und zugleich eine große Chance darstellt. Durch weitere Forschung in diesem Bereich kann die Übertragbarkeit auf reale Anwendungsfälle verbessert werden und die Nutzung synthetischer Daten einen maßgeblichen Beitrag zur automatisierten Fehlererkennung und -klassifizierung leisten, was insbesondere bei der Fernüberwachung von Maschinen von hoher Relevanz ist.

\section{Einordnung und Ausblick}
Trotz der begrenzten Übertragbarkeit auf reale Daten wurde das zentrale Ziel dieser Arbeit erreicht: Die entwickelte Pipeline konnte erfolgreich synthetische Bilddaten inklusive Annotationen generieren und für das Training von \ac{KI}-Modellen aufbereiten. Die gute Performance der \ac{YOLO}-Modelle auf dem synthetischen Datensatz unterstreicht die Konsistenz und Eignung der generierten Daten für das Training solcher Modelle. Die in Kapitel \ref{sec:problemstellung} gestellte Forschungsfrage konnte durch das entwickelte Artefakt, dessen Evaluation sowie kritische Diskussion beantwortet werden.

Die schwache Performance auf realen Daten verdeutlicht jedoch die Auswirkungen des bestehenden \textit{Domain Gaps} und zeigt somit auf konkrete Handlungsfelder für die weitere Forschung auf. Dazu zählen der Einsatz effizienterer Simulationssoftware, eine stärkere Recheninfrastruktur, alternative generative Verfahren (z.B. Diffusionsmodelle) sowie die Untersuchung weiterer Modellarchitekturen und Trainingsansätze, um die Übertragbarkeit von synthetischen Daten auf reale Anwendungsfälle zu verbessern und den \textit{Domain Gap} zu schließen.

Insgesamt bestätigt die Arbeit, dass synthetische Daten ein wertvolles Werkzeug für das Training von \ac{KI}-Modellen darstellen. Ihre erfolgreiche Integration in der industriellen Praxis erfordert jedoch zusätzliche Investitionen in Datenqualität, Modellgröße und Trainingsstrategien.
